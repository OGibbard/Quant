{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cffdea6-8391-480d-b9da-2209e1a89b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea5356c-3378-4f30-aa33-fa033d818003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'The Shawshank Redemption'}, {'title': 'The Godfather'}, {'title': 'The Dark Knight'}, {'title': 'The Godfather Part II'}, {'title': '12 Angry Men'}, {'title': \"Schindler's List\"}, {'title': 'The Lord of the Rings: The Return of the King'}, {'title': 'Pulp Fiction'}, {'title': 'The Lord of the Rings: The Fellowship of the Ring'}, {'title': 'The Good, the Bad and the Ugly'}]\n"
     ]
    }
   ],
   "source": [
    "option = webdriver.ChromeOptions()\n",
    "# I use the following options as my machine is a window subsystem linux. \n",
    "# I recommend to use the headless option at least, out of the 3\n",
    "option.add_argument('--headless')\n",
    "option.add_argument('--no-sandbox')\n",
    "option.add_argument('--disable-dev-sh-usage')\n",
    "# Replace YOUR-PATH-TO-CHROMEDRIVER with your chromedriver location\n",
    "driver = webdriver.Chrome(service=Service())\n",
    " \n",
    "page = driver.get('https://www.imdb.com/chart/top/') # Getting page HTML through request\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser') # Parsing content using beautifulsoup\n",
    " \n",
    "totalScrapedInfo = [] # In this list we will save all the information we scrape\n",
    "links = soup.select(\"table tbody tr td.titleColumn a\") # Selecting all of the anchors with titles\n",
    "first10 = links[:10] # Keep only the first 10 anchors\n",
    "for anchor in first10:\n",
    "    driver.get('https://www.imdb.com/' + anchor['href']) # Access the movieâ€™s page\n",
    "    scrapedInfo = {\n",
    "        \"title\": anchor.text\n",
    "    }\n",
    "    totalScrapedInfo.append(scrapedInfo)\n",
    "print(totalScrapedInfo) # Display the list with all the information we scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f89a045-e8da-4bd7-964b-c8c2d1906f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption\n",
      "The Godfather\n",
      "The Dark Knight\n",
      "The Godfather Part II\n",
      "12 Angry Men\n",
      "Schindler's List\n",
      "The Lord of the Rings: The Return of the King\n",
      "Pulp Fiction\n",
      "The Lord of the Rings: The Fellowship of the Ring\n",
      "The Good, the Bad and the Ugly\n"
     ]
    }
   ],
   "source": [
    "file = open('movies.txt', 'w')\n",
    "for movie in totalScrapedInfo:\n",
    "    print(*movie.values())\n",
    "    file.write(str(*movie.values())+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641299b-1442-4e4d-94f4-d720d57539e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
